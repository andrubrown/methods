{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import slate\n",
    "import codecs\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting plain text from text-embedded PDFs\n",
    "\n",
    "In [Module 1](https://diging.atlassian.net/wiki/pages/viewpage.action?pageId=4358148), we briefly touched on the problem of extracting usable plain-text content from PDF documents. In this notebook, we will use a Python package called [slate](https://github.com/timClicks/slate) to extract text from PDF documents that have embedded text (see Module 1 for details on what that means).\n",
    "\n",
    "## Start with one file\n",
    "\n",
    "Like most things in life, you should try to do the whole job all the way through until you're fairly certain of the procedure. So, we'll start with a single file.\n",
    "\n",
    "First we have to open the file. The [open()](https://docs.python.org/2/library/codecs.html#codecs.open) function creates a [``file``](https://docs.python.org/2/library/stdtypes.html#bltin-file-objects) object. You can open a file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open('../data/example.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you have to remember to close the file!! If you don't, Bad Things Will Happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to open a file is to use a [``with``](https://docs.python.org/2/reference/compound_stmts.html#with) statement. The basic idea is that we can open the file, do some procedures (in the indented block), and then the file will be automatically closed after the end of the indented block. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.pdf') as f:\n",
    "    pass    # do something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the PDF document with slate, we use slate's PDF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.pdf') as f:\n",
    "    extracted_text = slate.PDF(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a PDF object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c',\n",
       " 'I must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c',\n",
       " 'I must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, it's text! Notice that the text is actually represented by a list of strings. Each page is represented as a separate string; how nice! If I wanted to keep these pages separate, I could save each one as a separate text file. Or I could stitch them together into a single string, and save the document as one text file.\n",
    "\n",
    "To stitch the pages together, I could use the the [join()](https://docs.python.org/2/library/stdtypes.html#str.join) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This concatenates the pages, with two newlines intervening between them.\n",
    "joined = \"\\n\\n\".join(extracted_text)    \n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all of those pesky special characters? e.g. ``\\xe2\\x80\\x99`` ? ``\\xe2\\x80\\x99`` is a fancy-looking apostrophe. That means that there was some unicode data in the document -- that is, characters that aren't represented in the default ASCII encoding (basically just the keys on your keyboard). When we use the default ``open`` command to read a file, we just read everything in as ASCII. If we don't convert this string to its proper encoding, we'll run into Big Problems in the future.\n",
    "\n",
    "We will decode the string that we retrieved from our document using the ``decode()`` method. Well first try the UTF-8 encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\u2019s kick and the wind\\u2019s song and the white sail\\u2019s shaking,And a grey mist on the sea\\u2019s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\ufb02ying,And the \\ufb02ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\u2019s way and the whale\\u2019s way where the wind\\u2019s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\u2019s over.\\x0c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of ``\\xe2\\x80\\x99``, we see ``\\u2019``. Success! If we had gotten the encoding wrong, those characters would not have been transformed successfully. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.decode('latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step is to write this text to a file. We can ``open()`` a new file (one that doesn't exist yet), and write to it. Note the ``'w'`` that we are passing to ``open()`` -- that means that we want to open the file for writing. We also state that we want to use UTF-8 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(joined.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to find and open the text file at the path above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a whole bunch of PDFs\n",
    "\n",
    "Now let's scale up. We'll assume that we have a folder containing all of our PDFs. First we have to generate a list of all of the files in that folder. Then we have to iterate over all of those files, and extract the text (as above), and write the text into a new set of files that we can use in our computational workflow.\n",
    "\n",
    "The [os](https://docs.python.org/2/library/os.html) package has a handy method called [listdir()](https://docs.python.org/2/library/os.html#os.listdir) that will give us a list of files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example2.pdf', 'example3.pdf', 'example4.pdf', 'example5.pdf']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/PDFs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate the full paths to these files using the ``os.join()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/PDFs/example2.pdf\n",
      "../data/PDFs/example3.pdf\n",
      "../data/PDFs/example4.pdf\n",
      "../data/PDFs/example5.pdf\n"
     ]
    }
   ],
   "source": [
    "base_path = '../data/PDFs/'\n",
    "for filename in os.listdir(base_path):\n",
    "    print os.path.join(base_path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we want to apply our procedure to each of these files: \n",
    "* open the file, \n",
    "* extract the text with ``slate``,\n",
    "* join the pages together into a single string,\n",
    "* create a new text file,\n",
    "* and write the string into that file.\n",
    "\n",
    "It's a good idea to create a new folder to hold the new text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_basepath = '../data/PDFs_extracted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the action.\n",
    "\n",
    "------ ------\n",
    "**Update:** Most of the problems that we encountered were the result of errors in an older version of ``slate``. Make sure that you have the most recent version of slate by running the following on your command line:\n",
    "\n",
    "```bash\n",
    "$ pip install -U slate\n",
    "...\n",
    "$ pip show slate\n",
    "```\n",
    "\n",
    "If that doesn't work, you can also install the most recent version of the package directly from GitHub:\n",
    "\n",
    "```bash\n",
    "$ pip install git+git://github.com/timClicks/slate.git\n",
    "```\n",
    "\n",
    "The code below has been modified to correct a few common errors. This takes considerably longer to run, but should result in much cleaner extractions.\n",
    "------ ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 9, 10, and 13 are \\t, \\n, and \\r, respectively.\n",
    "m = dict.fromkeys([c for c in range(32) if c not in [9, 10, 13]])\n",
    "problems = []\n",
    "basepath = '../data/PDFs/'   # Folder containing PDF files.\n",
    "for filename in os.listdir(basepath):\n",
    "    filepath = os.path.join(basepath, filename)\n",
    "    \n",
    "    try:\n",
    "        # Open the file.\n",
    "        with codecs.open(filepath, 'r') as f:\n",
    "            # Extract the text.\n",
    "            extracted_text = slate.PDF(f)\n",
    "    except:\n",
    "        problems.append((filename, \"Slate couldn't open the PDF\"))\n",
    "        continue\n",
    "        \n",
    "    # Correct over-spaced text (i.e. individual characters are separated by spaces).\n",
    "    for i, page in enumerate(extracted_text):\n",
    "        if np.mean([len(c) for c in page.split()]) < 2.:\n",
    "            extracted_text[i] = re.sub('[ \\t]{2,}', '_', page).replace(' ', '').replace('_', ' ')\n",
    "        extracted_text[i] = re.sub('[ \\t]{2,}', ' ', re.sub('[\\n]{2,}', ' ', extracted_text[i]))\n",
    "    \n",
    "    # Join the pages, and decode.\n",
    "    joined_text = '\\n\\n\\n'.join(extracted_text)\n",
    "    # The ``.translate(m)`` bit removes control characters.\n",
    "    joined_text = joined_text.decode('utf-8').translate(m)\n",
    "    \n",
    "    # Figure out where to put the new text file.\n",
    "    #  Updated to clean the filename -- NLTK chokes on non-ASCII filenames.\n",
    "    textname = unidecode.unidecode(filename.replace('pdf', 'txt').decode('utf-8').translate(m))\n",
    "    textpath = os.path.join(text_basepath, textname)\n",
    "    \n",
    "    # Open (create) the new text file\n",
    "    with codecs.open(textpath, 'w', encoding='utf-8') as f:\n",
    "        # Write the string to the file.\n",
    "        f.write(joined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to open the corpus with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = nltk.corpus.PlaintextCorpusReader(text_basepath, '.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whoops = nltk.Text(documents.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      " is originally rid of a cover . The change in that is that red weakens an hour\n",
      "t is that red weakens an hour . The change has come . There is no search . But\n",
      "ng . A SUBSTANCE IN A CUSHION . The change of color is likely and a difference\n",
      "nt as many girls as men . Does this change . It shows that dirt is clean when \n",
      "over . Supposing you do not like to change , supposing it is very clean that t\n",
      "g it is very clean that there is no change in appearance , supposing that ther\n",
      "nd the same red with purple makes a change . It shows that there is no mistake\n",
      "f inside is let in and there places change then certainly something is upright\n",
      "nd no coffee , not even a card or a change to incline each way , a plan that h\n",
      "tering counting . It does , it does change in more water . Supposing a single \n",
      "the bottom . A piece of crystal . A change , in a change that is remarkable th\n",
      " piece of crystal . A change , in a change that is remarkable there is no reas\n",
      "re so is relaxed and yet there is a change , a news is pressing . A LITTLE CAL\n",
      "le steadiness . Is it likely that a change . A table means more than a glass e\n",
      "ing there is no wagon . There is no change lighter . It was done . And then th\n",
      "were not all in place . They had no change . They were not respected . They we\n",
      "ndensed . It was spread there . Any change was in the ends of the centre . A h\n",
      "e . A heap was heavy . There was no change . Burnt and behind and lifting a te\n",
      "e and sweet and yet there comes the change , there comes the time to press mor\n",
      "s perfect denial does make the time change all the time . The sister was not a\n",
      "there would be if there had been no change . A little sign of an entrance is t\n",
      "d uselessly . Any little thing is a change that is if nothing is wasted in tha\n",
      "ot and the insistence is marked . A change is in a current and there is no hab\n",
      "corners are gathered together . The change is mercenary that settles whitening\n",
      "it is and where it is in place . No change is not needed . That does show desi\n"
     ]
    }
   ],
   "source": [
    "whoops.concordance('change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
