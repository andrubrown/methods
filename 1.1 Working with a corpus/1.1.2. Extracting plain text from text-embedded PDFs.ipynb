{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import slate\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting plain text from text-embedded PDFs\n",
    "\n",
    "In [Module 1](https://diging.atlassian.net/wiki/pages/viewpage.action?pageId=4358148), we briefly touched on the problem of extracting usable plain-text content from PDF documents. In this notebook, we will use a Python package called [slate](https://github.com/timClicks/slate) to extract text from PDF documents that have embedded text (see Module 1 for details on what that means).\n",
    "\n",
    "## Start with one file\n",
    "\n",
    "Like most things in life, you should try to do the whole job all the way through until you're fairly certain of the procedure. So, we'll start with a single file.\n",
    "\n",
    "First we have to open the file. The [open()](https://docs.python.org/2/library/codecs.html#codecs.open) function creates a [``file``](https://docs.python.org/2/library/stdtypes.html#bltin-file-objects) object. You can open a file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open('../data/example.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you have to remember to close the file!! If you don't, Bad Things Will Happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to open a file is to use a [``with``](https://docs.python.org/2/reference/compound_stmts.html#with) statement. The basic idea is that we can open the file, do some procedures (in the indented block), and then the file will be automatically closed after the end of the indented block. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.pdf') as f:\n",
    "    pass    # do something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the PDF document with slate, we use slate's PDF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.pdf') as f:\n",
    "    extracted_text = slate.PDF(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a PDF object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c',\n",
       " 'I must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c',\n",
       " 'I must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, it's text! Notice that the text is actually represented by a list of strings. Each page is represented as a separate string; how nice! If I wanted to keep these pages separate, I could save each one as a separate text file. Or I could stitch them together into a single string, and save the document as one text file.\n",
    "\n",
    "To stitch the pages together, I could use the the [join()](https://docs.python.org/2/library/stdtypes.html#str.join) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This concatenates the pages, with two newlines intervening between them.\n",
    "joined = \"\\n\\n\".join(extracted_text)    \n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all of those pesky special characters? e.g. ``\\xe2\\x80\\x99`` ? ``\\xe2\\x80\\x99`` is a fancy-looking apostrophe. That means that there was some unicode data in the document -- that is, characters that aren't represented in the default ASCII encoding (basically just the keys on your keyboard). When we use the default ``open`` command to read a file, we just read everything in as ASCII. If we don't convert this string to its proper encoding, we'll run into Big Problems in the future.\n",
    "\n",
    "We will decode the string that we retrieved from our document using the ``decode()`` method. Well first try the UTF-8 encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\u2019s kick and the wind\\u2019s song and the white sail\\u2019s shaking,And a grey mist on the sea\\u2019s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\ufb02ying,And the \\ufb02ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\u2019s way and the whale\\u2019s way where the wind\\u2019s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\u2019s over.\\x0c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of ``\\xe2\\x80\\x99``, we see ``\\u2019``. Success! If we had gotten the encoding wrong, those characters would not have been transformed successfully. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I must go down to the seas again, to the lonely sea and the sky,And all I ask is a tall ship and a star to steer her by;And the wheel\\xe2\\x80\\x99s kick and the wind\\xe2\\x80\\x99s song and the white sail\\xe2\\x80\\x99s shaking,And a grey mist on the sea\\xe2\\x80\\x99s face, and a grey dawn breaking.\\x0c\\n\\nI must go down to the seas again, for the call of the running tideIs a wild call and a clear call that may not be denied; And all I ask is a windy day with the white clouds \\xef\\xac\\x82ying,And the \\xef\\xac\\x82ung spray and the blown spume, and the sea-gulls crying. \\x0c\\n\\nI must go down to the seas again, to the vagrant gypsy life,To the gull\\xe2\\x80\\x99s way and the whale\\xe2\\x80\\x99s way where the wind\\xe2\\x80\\x99s like a whetted knife;And all I ask is a merry yarn from a laughing fellow-rover,And quiet sleep and a sweet dream when the long trick\\xe2\\x80\\x99s over.\\x0c'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.decode('latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step is to write this text to a file. We can ``open()`` a new file (one that doesn't exist yet), and write to it. Note the ``'w'`` that we are passing to ``open()`` -- that means that we want to open the file for writing. We also state that we want to use UTF-8 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('../data/example.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(joined.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to find and open the text file at the path above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a whole bunch of PDFs\n",
    "\n",
    "Now let's scale up. We'll assume that we have a folder containing all of our PDFs. First we have to generate a list of all of the files in that folder. Then we have to iterate over all of those files, and extract the text (as above), and write the text into a new set of files that we can use in our computational workflow.\n",
    "\n",
    "The [os](https://docs.python.org/2/library/os.html) package has a handy method called [listdir()](https://docs.python.org/2/library/os.html#os.listdir) that will give us a list of files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example2.pdf', 'example3.pdf', 'example4.pdf', 'example5.pdf']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/PDFs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate the full paths to these files using the ``os.join()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/PDFs/example2.pdf\n",
      "../data/PDFs/example3.pdf\n",
      "../data/PDFs/example4.pdf\n",
      "../data/PDFs/example5.pdf\n"
     ]
    }
   ],
   "source": [
    "base_path = '../data/PDFs/'\n",
    "for filename in os.listdir(base_path):\n",
    "    print os.path.join(base_path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we want to apply our procedure to each of these files: \n",
    "* open the file, \n",
    "* extract the text with ``slate``,\n",
    "* join the pages together into a single string,\n",
    "* create a new text file,\n",
    "* and write the string into that file.\n",
    "\n",
    "It's a good idea to create a new folder to hold the new text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_basepath = '../data/PDFs_extracted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basepath = '../data/PDFs/'   # Folder containing PDF files.\n",
    "for filename in os.listdir(basepath):\n",
    "    filepath = os.path.join(basepath, filename)\n",
    "    # Open the file.\n",
    "    with codecs.open(filepath, 'r') as f:\n",
    "        # Extract the text.\n",
    "        extracted_text = slate.PDF(f)\n",
    "    \n",
    "    # Join the pages, and decode.\n",
    "    joined_text = \"\\n\\n\".join(extracted_text).decode('utf-8')\n",
    "    \n",
    "    # Figure out where to put the new text file.\n",
    "    textpath = os.path.join(text_basepath, filename.replace('pdf', 'txt'))\n",
    "    \n",
    "    # Open (create) the new text file\n",
    "    with codecs.open(textpath, 'w', encoding='utf-8') as f:\n",
    "        # Write the string to the file.\n",
    "        f.write(joined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to open the corpus with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = nltk.corpus.PlaintextCorpusReader(text_basepath, '.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whoops = nltk.Text(documents.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 33 matches:\n",
      "lass and a cousin , a spectacle and nothing strange a single hurt color and an \n",
      "places not empty . They see cover . NOTHING ELEGANT . A charm a single charm is\n",
      "A kind of green a game in green and nothing ﬂ at nothing quite ﬂ at and more ro\n",
      "en a game in green and nothing ﬂ at nothing quite ﬂ at and more round , nothing\n",
      "nothing quite ﬂ at and more round , nothing a particular color strangely , noth\n",
      "hing a particular color strangely , nothing breaking the losing of no little pi\n",
      "between the circular side place and nothing else , nothing else . To choose it \n",
      "cular side place and nothing else , nothing else . To choose it is ended , it i\n",
      "show it , that it shows it and that nothing , that there is nothing , that ther\n",
      "it and that nothing , that there is nothing , that there is no more to do about\n",
      " , best to make the length tall and nothing broader , anything between the half\n",
      "es and this necessarily spread into nothing . Spread into nothing . A FIRE . Wh\n",
      "y spread into nothing . Spread into nothing . A FIRE . What was the use of a wh\n",
      "d treading , little leading mention nothing . Cough out cough out in the leathe\n",
      "because of a ﬂ oor it is because of nothing , it is not in a vision . A fact is\n",
      "ry much bigger . Changing that made nothing bigger , it did not make anything b\n",
      " not disagreeable . The reason that nothing is hidden is that there is no sugge\n",
      "ing is not any symbol . It suggests nothing . A sack that has no opening sugges\n",
      "tainly not it has been measured and nothing has been cut off and even if that h\n",
      "bune does not mean paper , it means nothing more than cake , it means more suga\n",
      "little thing is a change that is if nothing is wasted in that cellar . All the \n",
      "ands that have more use for it than nothing , and mildly not mildly a correctio\n",
      " that , they had a disappointment . Nothing aiming is a ﬂ ower , if ﬂ owers are\n",
      "to hurry the measure all this means nothing if there is singing , if there is s\n",
      "at there is overtaking , this means nothing precious , this means clearly that \n"
     ]
    }
   ],
   "source": [
    "whoops.concordance('nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
